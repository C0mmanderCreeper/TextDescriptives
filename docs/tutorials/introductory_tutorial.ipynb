{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory Tutorial\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/HLasse/TextDescriptives/blob/main/docs/tutorials/introductory_tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "TextDescriptives lets you quickly and easily calculate a large variety of statistics and metrics from texts. \n",
    "\n",
    "The package includes a number of components that make it easy to only spend time extracting exactly the metrics you care about.\n",
    "\n",
    "This tutorial introduces some of components available in TextDescriptives and how you can use them to quickly analyse a text corpus.\n",
    "For more information on the components, see the [documentation](https://hlasse.github.io/TextDescriptives/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "In this tutorial we'll use TextDescriptives to get a quick overview of the [SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection).\n",
    "The dataset contains 5572 SMS messages categorized as ham or spam. \n",
    "\n",
    "To start, let's load a `spacy` pipeline and add some components to it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import textdescriptives\n",
    "except:\n",
    "    !pip install \"textdescriptives[tutorials]\"\n",
    "\n",
    "# download spaCy model\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textdescriptives as td\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.add_pipe(\"textdescriptives/readability\")\n",
    "nlp.add_pipe(\"textdescriptives/dependency_distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on, whenever we pass a document through the spacy pipeline (`nlp`), TextDescriptives will add readability and dependency distance metrics to the document.\n",
    "\n",
    "Let's load the data and pass it through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textdescriptives.utils import load_sms_data\n",
    "\n",
    "df = load_sms_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp.pipe(df[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = td.extract_df(doc, include_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the metrics to the original dataframe\n",
    "df = df.join(metrics, how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all we need to do! Let's take a look at the dataframe and the metrics we have calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some quick exploratory data analysis to get a sense of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=\"label\", y=\"lix\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a quick test to see if any of our metrics correlate strongly with the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the label as a boolean\n",
    "df[\"is_ham\"] = df[\"label\"] == \"ham\"\n",
    "# compute the correlation between all metrics and the label\n",
    "metrics_correlations = metrics.corrwith(df[\"is_ham\"]).sort_values(key=abs, ascending=False)\n",
    "metrics_correlations[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's some pretty high correlations - let's plot a few of them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a kde plot for the top 3 metrics\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,3, figsize=(10, 5), sharey=False)\n",
    "for i, metric in enumerate(metrics_correlations.index[:3]):\n",
    "    sns.kdeplot(df, x=metric, hue=\"label\", ax=ax[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! We've now done a quick analysis of the SMS dataset and found the distributions of e.g. the standard deviation of token length, the number of characters, and the number of unique tokens to be distributed differently between the actual SMS's and spam. \n",
    "\n",
    "Next steps could be continue the exploratory data analysis or to build a simple classifier using the extracted metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fec3abd59d8d4e793464ce299b69082c8b9c618d555ba6df7044c7d7b4183f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
